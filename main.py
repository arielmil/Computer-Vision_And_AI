from NEAT import softmax, evaluate
import numpy as np
from dataset_transformer import images_dir
from dataset_manager import load_images_from_folder

from sklearn.model_selection import train_test_split

from tensorneat.pipeline import Pipeline
from tensorneat.algorithm import NEAT
from tensorneat.genome import DefaultGenome, DefaultMutation, DefaultCrossover, DefaultDistance, DefaultConn
from tensorneat.common import ACT, AGG
from tensorneat.genome.gene.node.bias import BiasNode
from tensorneat.problem.func_fit import CustomFuncFit

import pickle

# Carregar o dataset
X_data, y_data = [], []
for X_part, y_part in load_images_from_folder(images_dir, everything_at_once=False):
    X_data.append(X_part)
    y_data.append(y_part)

# Concatena os lotes de forma eficiente
X_data = np.concatenate(X_data, axis=0)
y_data = np.concatenate(y_data, axis=0)

# Converter labels para one-hot encoding
y_data = np.eye(10)[y_data]

# Dividir dataset em treino e teste (70% treino, 30% teste)
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)
print(f"Treino: {len(X_train)} amostras | Teste: {len(X_test)} amostras")

# Configura a arquitetura da rede neural
genome = DefaultGenome(
    num_inputs=20*20,  # N√∫mero de pixels da imagem (entrada)
    num_outputs=10,  # 10 classes (0-9)
    max_nodes = 30000, # N√∫mero m√°ximo de neur√¥nios
    max_conns = 250000, # N√∫mero m√°ximo de conex√µes
    mutation = DefaultMutation(), # Muta√ß√£o padr√£o
    crossover = DefaultCrossover(), # Crossover padr√£o
    distance = DefaultDistance(), # Dist√¢ncia padr√£o
    init_hidden_layers=(),  # Deixa o NEAT evoluir a estrutura oculta
    node_gene=BiasNode(
        activation_options=[ACT.sigmoid],  # Ativa√ß√£o Sigmoid nos neur√¥nios ocultos
        aggregation_options=[AGG.sum, AGG.product],  # Op√ß√µes de agrega√ß√£o
    ),
    conn_gene = DefaultConn(), # Conex√£o padr√£o
    output_transform=softmax,  # Softmax na sa√≠da para classifica√ß√£o multiclasse
)

custom_problem = CustomFuncFit(
    func=evaluate,
    low_bounds=[0] * 400,   # Imagens normalizadas entre [0,1]
    upper_bounds=[1] * 400,
    method="sample",
    num_samples= X_train.shape[0]  # Quantidade de amostras usadas por gera√ß√£o
)

# Configura o algoritmo NEAT
algorithm = NEAT(
    pop_size=200,  # Tamanho da popula√ß√£o
    species_size=20,  # N√∫mero de esp√©cies na popula√ß√£o
    survival_threshold=0.01,  # Percentual de sobreviv√™ncia por gera√ß√£o
    genome=genome,  # Usa o genoma configurado
)

# Configurar e rodar o pipeline NEAT
pipeline = Pipeline(
    algorithm=algorithm,
    problem=custom_problem,
    generation_limit=50,
    fitness_target=-0.01,
    seed=42,
)

# Inicializar o estado do NEAT
state = pipeline.setup()

# Executar evolu√ß√£o
state, best = pipeline.auto_run(state)

pipeline.show(state, best)

# Testar a melhor rede neural no conjunto de teste
network = algorithm.genome.network_dict(state, *best)
algorithm.genome.visualize(network, save_path="./imgs/network.svg")
#test_predictions = np.array([best_network(x) for x in X_test])

# Calcular acur√°cia
test_accuracy = np.mean(np.argmax(test_predictions, axis=1) == np.argmax(y_test, axis=1))
print(f"üéØ Acur√°cia final no conjunto de teste: {test_accuracy * 100:.2f}%")

# Salvar modelo treinado
with open("best_neat_model.pkl", "wb") as f:
    pickle.dump(best, f)
print("‚úÖ Modelo salvo como 'best_neat_model.pkl'")